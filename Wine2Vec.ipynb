{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine2Vec Exploration\n",
    "##### By Zack Thoutt\n",
    "\n",
    "Here is a little data exploration of my new wine review dataset using word2vec. My theory is that the words a sommelier would use to describe a wine (oaky, tannic, acidic, berry, etc.) can be used to predict the type of wine (Pinot Noir, Cabernet Sav., etc.). Let's see if we can extract some interesting relationships from the data and somewhat validate this theory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import sklearn.manifold\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import gensim.models.word2vec as w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Get the Data\n",
    "The dataset can be found on [Kaggle](https://www.kaggle.com/zynicide/wine-reviews) or you can run my sraper on [Github](https://github.com/zackthoutt/wine-deep-learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('dataset/winemag-data-130k-v2.json', dtype={\n",
    "    'points': np.int32,\n",
    "    'price': np.float32,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['variety']\n",
    "descriptions = data['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Data\n",
    "There are several hundred fairly common varietals of wine and probably thousands of other niche varietals. It will be difficult to be able to identify them all, but I hypothesize that it should be possible to classify the most common, say, 50 or 100 wine varietals with this wine review dataset. \n",
    "\n",
    "Let's take a look at a few reviews and see if we as humans can tell a difference in the descriptive words used for different types of wine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White Blend   :   Aromas include tropical fruit, broom, brimstone and dried herb. The palate isn't overly expressive, offering unripened apple, citrus and dried sage alongside brisk acidity.\n",
      "Chardonnay   :   This is weighty, creamy and medium to full in body. It has plenty of lime and pear flavors, plus slight brown sugar and vanilla notes.\n",
      "Grüner Veltliner   :   Freshness characterizes the nose: green pear, ivy leaves and citrus notes play on nose and palate. This is light footed, easy drinking and charming. Drink soon while flavors are fresh.\n"
     ]
    }
   ],
   "source": [
    "print('{}   :   {}'.format(labels.tolist()[0], descriptions.tolist()[0]))\n",
    "print('{}   :   {}'.format(labels.tolist()[56], descriptions.tolist()[56]))\n",
    "print('{}   :   {}'.format(labels.tolist()[93], descriptions.tolist()[93]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if you're not someone who knows wine, I think that there is a pretty clear distinction in the descriptions of these different types of wines. The Cabernet Sauvignon (a red wine) was described with words like cherry, tannin and carmel. The next two reviews are white wines, but even they show differences in their description. The sauvignon blanc is described as minerally, citrus, and green fruits while the chardonnay is described as smokey, earthy, crisp-apple, and buttery. This provides us with good motivation to move forward and explore the data more.\n",
    "\n",
    "One of the limitations that I think we will have with this dataset is that there will be a lot more reviews for popular wine varietals than less popular wine varietals. This isn't bad neccissarily, but it means that we will probably only be able to classify the most popular N varietals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinot Noir                       13272\n",
      "Chardonnay                       11753\n",
      "Cabernet Sauvignon                9472\n",
      "Red Blend                         8946\n",
      "Bordeaux-style Red Blend          6915\n",
      "Riesling                          5189\n",
      "Sauvignon Blanc                   4967\n",
      "Syrah                             4142\n",
      "Rosé                              3564\n",
      "Merlot                            3102\n",
      "Nebbiolo                          2804\n",
      "Zinfandel                         2714\n",
      "Sangiovese                        2707\n",
      "Malbec                            2652\n",
      "Portuguese Red                    2466\n",
      "White Blend                       2360\n",
      "Sparkling Blend                   2153\n",
      "Tempranillo                       1810\n",
      "Rhône-style Red Blend             1471\n",
      "Pinot Gris                        1455\n",
      "Champagne Blend                   1396\n",
      "Cabernet Franc                    1353\n",
      "Grüner Veltliner                  1345\n",
      "Portuguese White                  1159\n",
      "Bordeaux-style White Blend        1066\n",
      "Pinot Grigio                      1052\n",
      "Gamay                             1025\n",
      "Gewürztraminer                    1012\n",
      "Viognier                           996\n",
      "Shiraz                             836\n",
      "Petite Sirah                       770\n",
      "Sangiovese Grosso                  751\n",
      "Barbera                            721\n",
      "Glera                              709\n",
      "Port                               668\n",
      "Grenache                           651\n",
      "Corvina, Rondinella, Molinara      619\n",
      "Chenin Blanc                       591\n",
      "Tempranillo Blend                  588\n",
      "Carmenère                          575\n",
      "Albariño                           477\n",
      "Pinot Blanc                        442\n",
      "Rhône-style White Blend            425\n",
      "Nero d'Avola                       365\n",
      "Aglianico                          359\n",
      "Moscato                            358\n",
      "Garnacha                           326\n",
      "Sauvignon                          316\n",
      "Verdejo                            294\n",
      "Melon                              280\n",
      "Name: variety, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "varietal_counts = labels.value_counts()\n",
    "print(varietal_counts[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you drink wine regularly you will probably recognize the most reviewed wines listed above. The value counts for different wine varietals does verify my theory that less popular wines might not have enough reviews to classify them. The most popular wine varietals have thousands of reviews, but even towards the bottom end of the top 50 wine varietals there are only a few hundred reviews. This isn't a problem for building a word2vec model like we are going to do next, but it is something to keep in mind as we move forward trying to create a wine classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec Model\n",
    "##### Formatting the Data\n",
    "In order to train a word2vec model, all of the description data will need to be concatenated into one giant string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_raw = \"\"\n",
    "for description in descriptions:\n",
    "    corpus_raw += description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"aromas include tropical fruit, broom, brimstone and dried herb. the palate isn't overly expressive, \""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_raw[:100].lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to tokenize the wine corpus using NLTK. This process will essentially break the word corpus into an array of sentences and then break each sentence into an array of words stripping out less usefull characters like commas and hyphens in the process. In this way, we are able to train the word2vec model with the context of sentences and relative word placement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sentences = tokenizer.tokenize(corpus_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_wordlist(raw):\n",
    "    clean = re.sub(\"[^a-zA-Z]\",\" \", raw)\n",
    "    words = clean.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for raw_sentence in raw_sentences:\n",
    "    if len(raw_sentence) > 0:\n",
    "        sentences.append(sentence_to_wordlist(raw_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The palate blends a gamy beef quality with oregano, marjoram, cooked strawberry, baked blackberry and a sesame-oil character.Black cherry, black plum and black currant are integrated well into the fresh dill and smoke scents on the nose of this wine from one of the region's newest properties.\n",
      "['The', 'palate', 'blends', 'a', 'gamy', 'beef', 'quality', 'with', 'oregano', 'marjoram', 'cooked', 'strawberry', 'baked', 'blackberry', 'and', 'a', 'sesame', 'oil', 'character', 'Black', 'cherry', 'black', 'plum', 'and', 'black', 'currant', 'are', 'integrated', 'well', 'into', 'the', 'fresh', 'dill', 'and', 'smoke', 'scents', 'on', 'the', 'nose', 'of', 'this', 'wine', 'from', 'one', 'of', 'the', 'region', 's', 'newest', 'properties']\n"
     ]
    }
   ],
   "source": [
    "print(raw_sentences[234])\n",
    "print(sentence_to_wordlist(raw_sentences[234]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The wine corpus contains 5,345,870 tokens\n"
     ]
    }
   ],
   "source": [
    "token_count = sum([len(sentence) for sentence in sentences])\n",
    "print('The wine corpus contains {0:,} tokens'.format(token_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some context, all of the GOT books combined make up only ~1,800,000 tokens, so this dataset is nearly 4x as large as the GOT book series.\n",
    "\n",
    "##### Training the Model\n",
    "It took some experimenting to get the model to train well. The main things hyperparameters that I had to tune were `min_word_count` and `context_size`. \n",
    "\n",
    "I usually train word2vec models with a `min_word_count` closer to 3-5, but since this dataset is so large I had to bump it up to 10. When I was training the model on a smaller `min_word_count` I was getting a lot of winery and vinyard noise in my word similarities (ie the words most similar to \"cherry\" were a bunch of foreign vinyards, wineries, regions, etc.). After looking through some of the descriptions I came to the conclusion that most of the wine descriptions don't mention the wine varietal, vinyard, or winery, but some do. So I played with the `min_word_count` until those rare instances had less of an effect on the model.\n",
    "\n",
    "I also had to play with the `context_size` quite a bit. 10 is a pretty large context size, but it makes sense here because really all of the words in a sentence are related to each other in the context of wine descriptions and what were are trying to accomplish. I might even experiment with bumping the `context_size` up higher at some point, but even now most of the words in each sentence will be associated with each other in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 300\n",
    "min_word_count = 10\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "context_size = 10\n",
    "downsampling = 1e-3\n",
    "seed=1993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine2vec = w2v.Word2Vec(\n",
    "    sg=1,\n",
    "    seed=seed,\n",
    "    workers=num_workers,\n",
    "    size=num_features,\n",
    "    min_count=min_word_count,\n",
    "    window=context_size,\n",
    "    sample=downsampling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine2vec.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec vocabulary length: 10097\n"
     ]
    }
   ],
   "source": [
    "print('Word2Vec vocabulary length:', len(wine2vec.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225096\n"
     ]
    }
   ],
   "source": [
    "print(wine2vec.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-43bd81550482>:1: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  wine2vec.train(sentences, total_examples=wine2vec.corpus_count, epochs=wine2vec.iter)\n"
     ]
    }
   ],
   "source": [
    "wine2vec.train(sentences, total_examples=wine2vec.corpus_count, epochs=wine2vec.iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing with the Model\n",
    "Now that we have a trained model we can get to the fun part and start playing around with the results. As you can tell from the outputs below, there is definitely still some noise in the data that could be worked out by tuning the parameters further, but overall we are getting pretty good results.\n",
    "\n",
    "##### Words closest to a given word\n",
    "\"melon,\" \"berry,\" and \"oak\" are words that someone might use to describe the taste/smell of a wine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine2vec.most_similar('melon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-103f02211a08>:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  wine2vec.most_similar('medicinal')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('reedy', 0.6594145894050598),\n",
       " ('pasty', 0.6149617433547974),\n",
       " ('underdeveloped', 0.606225848197937),\n",
       " ('scrubbing', 0.603406548500061),\n",
       " ('Medicinal', 0.6022852063179016),\n",
       " ('soupy', 0.5986312627792358),\n",
       " ('weedy', 0.5983495712280273),\n",
       " ('foxy', 0.5953934788703918),\n",
       " ('active', 0.5947179794311523),\n",
       " ('rubbing', 0.5925801396369934)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine2vec.most_similar('medicinal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vanillins', 0.5344773530960083),\n",
       " ('woodsap', 0.5198507905006409),\n",
       " ('charry', 0.47783029079437256),\n",
       " ('cloaked', 0.4773528575897217),\n",
       " ('elaborated', 0.4762468934059143),\n",
       " ('regime', 0.4708051383495331),\n",
       " ('jacket', 0.46834731101989746),\n",
       " ('oaky', 0.4653569459915161),\n",
       " ('application', 0.4612783193588257),\n",
       " ('puncheons', 0.45585477352142334)]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine2vec.most_similar('oak')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing that someone might use to describe a wine is how acidic it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('raspingly', 0.5183893442153931),\n",
       " ('tartly', 0.4958021938800812),\n",
       " ('acidically', 0.49269402027130127),\n",
       " ('sheering', 0.49023425579071045),\n",
       " ('unforgiving', 0.48199647665023804),\n",
       " ('angular', 0.4760863184928894),\n",
       " ('pinching', 0.47394663095474243),\n",
       " ('pointy', 0.47168493270874023),\n",
       " ('ultracrisp', 0.46784496307373047),\n",
       " ('frisky', 0.4669594466686249)]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine2vec.most_similar('acidic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or what the body is like. \"full-bodied\" would be something that is thick like whole milk while \"light-bodied\" would be something that is thin like skim milk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Full', 0.584251880645752),\n",
       " ('creamily', 0.4710482656955719),\n",
       " ('voluminous', 0.4688924551010132),\n",
       " ('fulfilling', 0.46560823917388916),\n",
       " ('bodied', 0.46444156765937805),\n",
       " ('expectedly', 0.4592348337173462),\n",
       " ('fullish', 0.4530738592147827),\n",
       " ('mouthfilling', 0.44827550649642944),\n",
       " ('explosively', 0.443299263715744),\n",
       " ('robustly', 0.4367332458496094)]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine2vec.most_similar('full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can also feel in your mouth how much tannin a wine has. Wines with lots of tannis give you a dry, furry feeling on your tounge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Tannins', 0.6397914290428162),\n",
       " ('tannin', 0.5773420333862305),\n",
       " ('resistance', 0.5176475644111633),\n",
       " ('pliant', 0.5133403539657593),\n",
       " ('Wrapped', 0.5123817920684814),\n",
       " ('furry', 0.5082734823226929),\n",
       " ('tannic', 0.5056681632995605),\n",
       " ('unobtrusive', 0.49775996804237366),\n",
       " ('negotiable', 0.4963838756084442),\n",
       " ('vise', 0.48365217447280884)]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine2vec.most_similar('tannins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear relationships between word pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nearest_similarity_cosmul(start1, end1, end2):\n",
    "    similarities = wine2vec.most_similar_cosmul(\n",
    "        positive=[end2, start1],\n",
    "        negative=[end1]\n",
    "    )\n",
    "    start2 = similarities[0][0]\n",
    "    print(\"{start1} is related to {end1}, as {start2} is related to {end2}\".format(**locals()))\n",
    "    return start2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oak is related to vanilla, as cedar is related to cherry\n"
     ]
    }
   ],
   "source": [
    "nearest_similarity_cosmul('oak', 'vanilla', 'cherry');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full is related to berry, as Unoaked is related to light\n"
     ]
    }
   ],
   "source": [
    "nearest_similarity_cosmul('full', 'berry', 'light');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tannins is related to plum, as refreshing is related to fresh\n"
     ]
    }
   ],
   "source": [
    "nearest_similarity_cosmul('tannins', 'plum', 'fresh');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full is related to bodied, as pinching is related to acidic\n"
     ]
    }
   ],
   "source": [
    "nearest_similarity_cosmul('full', 'bodied', 'acidic');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "I think that exploring this wine2vec model has helped validate the theory that there is a lot of useful data in these wine descriptions that can probably be used to classify wine varietals. I have not yet trained any classifiers, but we saw early on that descriptions of different wines used different words to describe the wine varietals, and based on our wine2vec model there is definitley enough context to link these descriptive words together and come up with something to classify them when they are used in certain combinations.\n",
    "\n",
    "That's all I have for now. As always, let me know if anyone has any questions, comments, insights, ideas, etc. I'll be posting more of my analyses and models soon!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
